# HSE Deep Learning in NLP Course
Курс по глубокому обучению в нлп для магистров компьютерной лингвистики ВШЭ

# Важные ссылки
[Страничка на сайте ВШЭ](https://www.hse.ru/edu/courses/292673762)

[Канал с объявлениями](https://t.me/hse_dl_nlp)

[Чат](https://t.me/joinchat/Bp0V0UPTLBJHv3o7XiBFaA)

[Обзор проектов, которые можно сделать](https://youtu.be/TLauwjPkbS0)

# Дополнительные материалы

- [Сравнение логистической регрессии и MLP](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_01/LogReg%20vs%20MLP.ipynb)
- [Производные некоторых функций](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_01/derivatives.ipynb)
- [Дополнение к сделанной первой домашке](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_01/neural_network/numpy%20MNIST.ipynb)
- [Предобработка корпуса](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_02/1.1%20Processing%20corpus.ipynb)
- [Имплементация RNN, LSTM, Bidirectional](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_03/modeling.py)
- [Тестирование имплементации выше на корректность размерностей](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_03/Implementation%20test.ipynb)
- [Attention from scratch](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_05/Attention%20from%20scratch.ipynb)
- [Введение в PyTorch через CIFAR 10 для DMIA](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_06/Hello%20CIFAR%2010.ipynb)
- [От numpy до PyTorch для DMIA](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_06/Hello%20PyTorch.ipynb)

# Syllabus

# Lecture 1 - Neural Networks

### Видео
[Первая лекция вкратце](https://youtu.be/jEMdv9fW2ZA)  
[Видео про производные](https://youtu.be/tZ0yCzWfbZc)  

### Слайды
[Neural Networks](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_01/Week%2001.pdf)

### Домашка
[n_layer neural network](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_01/neural_network/Homework%201.1.ipynb)
10 баллов, дедлайн - 30.09.2019 23:59

# Lecture 2 - Word Embeddings

### Видео
[Занятие, первая часть](https://www.youtube.com/watch?v=xjJF5NHFBAY&feature=youtu.be)  
[Занятие, вторая часть](https://www.youtube.com/watch?v=UkEFhFtzgAI&feature=youtu.be)  

### Слайды
[Word Embeddings](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_02/Week%2002.pdf)

### Домашка
[word2vec](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_02/1.2%20word2vec.ipynb)
10 баллов, дедлайн - 07.10.2019 23:59

# Lecture 3 - Tricks in Deep Learning, Recurrent Neural Networks, Convolutional Neural Networks
 
### Видео
[Занятие, первая часть](https://youtu.be/Uz5z0NLi70w)  
[Занятие, вторая часть](https://youtu.be/L0jfQ_n6SjI)   
[Занятие, третья часть](https://youtu.be/yF7bDSmfyII) 

### Слайды
[Tricks in Deep Learning](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_03/Tricks%20in%20DL.pdf)  
[Recurrent Neural Networks](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_03/RNN.pdf)  
[Convolutional Neural Networks](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_03/CNN.pdf)

# Lecture 4 - Language Models
 
### Видео
[Занятие, первая часть](https://youtu.be/VSYG-xMG94U)   
[Занятие, вторая часть](https://youtu.be/9WnUSoyBzfs) 

### Слайды
[Language Models](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_04/Language%20Models.pdf)  

# Lecture 5 - Sequence2Sequence, Attention
 
### Видео

[Занятие, первая часть](https://youtu.be/LOH3hx8skMU)   
[Занятие, вторая часть](https://youtu.be/UEu_cWY2v2M)   
[Занятие, третья часть](https://youtu.be/mWZ2FvYmSco)   

### Слайды
[Transformer](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_05/Transformer.pdf)  

### Домашка
[classification](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_05/Classification%20Subsample%20Mail.ipynb)
10 баллов, дедлайн - 24.10.2019 23:59

# Lecture 6 - GPT, BERT, Metric Learning
 
### Видео

[Занятие, первая часть](https://www.youtube.com/watch?v=kizuKRzG2Rs)   
[Занятие, вторая часть](https://www.youtube.com/watch?v=gMBSPvTg0Gg)   
[Занятие, третья часть](https://www.youtube.com/watch?v=Wxi8cupTx9Q)   
[Занятие, четвертая часть](https://www.youtube.com/watch?v=klOSrqiCE8g)   

### Слайды
[BERT](https://github.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/blob/master/week_06/BERT.pdf)  

# Дефолтный проект
[Соревнование на kaggle](https://www.kaggle.com/c/deepnlp-hse-course/overview) на основе [ответов mail.ru](https://otvet.mail.ru/)

## Задача
**Техническая задача:** предсказать main_category вопроса.  
**Продуктовая задача:** улучшить клиентский опыт за счет предсказания категории вопроса. 

## Продуктовое описание
Сейчас человеку самому необходимо выбрать одну из 28-ми верхнеуровневых категорий после того как он написал вопрос. Как правило, клиентам это неудобно и они могут ошибаться в выставлении категории. В итоге качество ответов к этому вопросу сильно понижается.

### Проблемы выставления не той категории:
- люди, задавшие вопрос, получают менее релевантные ответы;
- люди, которые ищут уже существующие вопросы, могут не получить ответа или получить слишком плохие/нерелеватные ответы;
- люди, которые отвечают на вопросы этой категории, не видят этого вопроса;
- люди, которые отвечают на вопросы неправильно выставленной категории, могут отвечать плохо и им приходится видеть не те вопросы;
- поисковая выдача загрязняется.

### Продуктовое решение
Нужно сделать классификатор, который будет по дефолту вставлять категорию, если классификатор достаточно уверен, либо, если не уверен, предлагать клиенту наиболее вероятные категории.

### Дополнительная информация
Это реальная продуктовая задача с огромным количеством способов решения. Решение сейчас внедряется в mail.ru group

Что можете попробовать:
- transfer learning;
- data augmentation;
- metric learning;
- pseudo labeling;
- multitask learning

# Требования к описанию своего проекта
Дедлайн проекта: 14/12/2019 либо 21/12/2019  
Описание проекта нужно к 16/11/2019 23:59 - чем позже вы сдаете, тем меньше у вас времени на реализацию
## Какая задача?
Проекты стенфордовского курса можно посмотреть [здесь](http://web.stanford.edu/class/cs224n/project.html).  
Опишите задачу. Важное пожелание: лаконичность. Максимум одна страница А4.
 Хочется понимать формат входных и выходных данных, что будете предсказывать. 
 Как вы поймете, что ваш проект удался, как все остальные поймут это,
  какие метрики вы будете трекать, зачем вы хотите решать эту задачу?   

Хорошая постановка задачи: 
- я реализую такой-то метод из такой-то статьи и получу метрики, которые максимум на столько-то уступают метрикам из статьи;
- я тестирую такую-то гипотезу (описание гипотезы), улучшая такую-то метрику;
- я решу такую-то задачу, трекая такую-то метрику;
- я улучшу бейзлайн решение (улучшу такую-то метрику на такой-то задаче) за счет трансфер лернинга/аугментаций/псевдолейблинга/дистилляции/тд
 (этот пункт подходит для соревнования).  

Плохая постановка задачи: 
- я стану круче/лучше/выше/сильнее/умнее; 
- пусть ничего не получится, главное поучаствую; 
- я не знаю;
- я лучше узнаю дип лернинг/нлп/торч; 
- ближе к концу дедлайна решу что хочу; 
- главное чтобы просто что-то начало учиться; 
- я попробую вот это и это, а еще вот это и может быть вот это; 
- в результате проекта у меня будет красивый ноутбучек/репозиторий.

 Хорошая формулировка имеет действие (что сделаю) и метрику (как я оценю то, что сделаю).
  В плохой формулировке тяжело или невозможно понять выполнили ли вы проект или нет.

Запишитесь в эту общую таблицу, чтобы проекты сильно не повторялись:
[Проекты - Google Таблицы](https://docs.google.com/spreadsheets/d/19iCgKFi__YUU_QLWhz-UxN97hUZ8xNvMcDdSle5Zm0U/edit?usp=sharing).  

Напишите что за задачу в общем случае решаете (классификация элементов последовательности,
 классификация небольших текстов, генерация текстов) и кейсы (примеры) вашей задачи, например вот так:  

Кейсы для NER’а  
Вход токенизированный текст: [Москва, -, красивый, город]  
Выход последовательность присвоенных классов специальных токенов: [B-LOC, O, O, O]  
Дальше небольшой экскурс в BIO разметку.
## Какие результаты по вашей задаче уже достигнуты?
Напишите как сейчас решают данную задачу и насколько успешно (метрики). 
Напишите краткий обзор существующих методов, на которые вы будете ссылаться или использовать как референс. 
Подумайте хватит ли у вас ресурсов для решения этой задачи. 
Помните, что те же языковые модели могут учиться несколько дней-неделю и большие модели сильно дольше.

Можно посмотреть что уже сделано по вашей задаче здесь: [Papers With Code : the latest in machine learning](https://paperswithcode.com/) и 
[nlpprogress](http://nlpprogress.com/)
## Какие датасеты будете использовать?
На каких данных сейчас решают задачу. 
Приложите ссылку на минимум 1 источник данных, который вы планируете использовать для тренировки/тестирования. 
Если данных конкретно сейчас нет, то где вы планируете искать или как организовывать датасет. 
Полезный сервис: [Dataset Search](https://toolbox.google.com/datasetsearch).

Не забудьте добавить описание датасета.

Сильно не советую самостоятельно парсить данные, 
но если у вас уже все есть и вы уверены, что сможете сделать это за пару дней, то почему бы и нет.
## Какой бейзлайн будет у вашего проекта?
Самая простая модель, которую вы можете реализовать для решения вашей задачи. 
В идеале делается за пару часов. Если бейзлайн слишком сложный, то найдите информацию о нем. 
Тот же [Papers With Code : the latest in machine learning](https://paperswithcode.com/) поможет.  

Бейзлайн нужен для того, чтобы понимать примерное качество, которое вы можете получить, решая эту задачу.
Часто полезно для настройки логирования, расчета и вывода метрик и прочих инженерных вещей, которые не зависят от модели.
Также бейзлайн полезен для понимания реализуете ли вы более серьезные методы правильно 
и имеет ли вообще ваш новый метод практическую ценность, нет ли у вас багов.  

Бейзлайн для классификации: tf-idf + log reg
## Какой у вас план?
Распишите roadmap (ориентировочный, не стоит забывать про здравый смысл и адекватность) 
и примерные сроки на каждый из пунктов на первые пару недель. 
Roadmap мы не фиксируем, вы сможете его менять, но он нужен для того, чтобы вы оценили ваши силы,
 примерно понимали что нужно сделать, 
 помогает понять сложность проекта, который вы выбрали.

Дальше мы будем работать недельными спринтами:
- Вы пишите план на неделю
- Рассказываете что удалось сделать на предыдущей неделе
- Мы обсуждаем текущие успехи
- Возможно, корректируем план

Таким образом вы сами определяете свою загруженность, мы понимаем ваш прогресс, у нас не возникает слишком непредвиденных ситуаций.
Это нужно для коррекции, чтобы вы не ставили себе на неделю нереальных или слишком простых задач (если вы не загруженны на этой неделе), 
а также, чтобы вы не вспомнили неожиданно за пару дней до сдачи про проект. 
Необязательно каждую неделю выдавать максимальный результат, но и оставлять все на потом тоже плохая идея.
У вас может быть загруженная неделя и мало задач по проекту, это нормально, но идея в том, 
чтобы вы не забывали и понимали на каком вы сейчас этапе и сколько осталось сделать.
В первую неделю стоит поставить построение бейзлайна как одну из задач и добычу датасета, если его нет. 

## FAQ
Q: У меня нет времени на проект. Что делать?  
A: Необязательно запускать ракету, можно выбрать проект по силам и временнЫм возможностям, но и не советую брать супер простой проект.

Q: У меня ничего не получилось. Это будет 0 баллов?  
A: За счет недельных планов каких-либо результатов достичь получится.

Q: Я не знаю какой проект выбрать. Что делать?  
A: Можно описать свои желания мне в личку, посмотреть здесь [Papers With Code : the latest in machine learning](https://paperswithcode.com/), поискать в интернете, спросить на работе какой проект вас прокачает, присоединиться к кому-нибудь.

# Связь с преподавателем
[bobazooba@yandex.ru](mailto:bobazooba@yandex.ru)  
[telegram: @bobazooba](https://t.me/bobazooba)
