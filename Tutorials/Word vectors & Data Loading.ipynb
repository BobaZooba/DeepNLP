{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# В этом туториале разберёмся с предобученными эмбеддингами и обработкой данных в `torch`\n",
    "\n",
    "## Источники\n",
    "\n",
    "- [fasttext](https://fasttext.cc/docs/en/crawl-vectors.html) для 157 языков\n",
    "- [RusVectores](https://rusvectores.org/ru/models/) – собрание предобученных эмбеддингов для русского языка на любой вкус *\n",
    "- Также мы можем предобучить эмбеддинги на своих данных, но об этом в следующих сериях :)\n",
    "\n",
    "-----\n",
    "\n",
    "\\* В моделях RusVectores в большинстве своём содержатся не сами слова и их векторы, а слово+частеречный тег (например, `мама_NOUN [вектор]` , что не так удобно в использовании для наших целей, но может пригодиться вам в исследованиях на других курсах. [Вот тут](https://github.com/RaRe-Technologies/gensim-data/issues/3) можно посмотреть как загружать модели RusVectores\n",
    "\n",
    "----\n",
    "Скачиваем и распаковываем fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Раскомментируйте и скачайте эмбеддинги\n",
    "# !wget  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
    "# !gzip -d cc.ru.300.vec.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words: 2000000, \n",
      "emb_dim: 300\n"
     ]
    }
   ],
   "source": [
    "emb_file = open('cc.ru.300.vec')\n",
    "\n",
    "num_words, emb_dim = emb_file.readline().split()\n",
    "num_words, emb_dim = int(num_words), int(emb_dim)\n",
    "emb_file.close()\n",
    "print(f'num_words: {num_words}, \\nemb_dim: {emb_dim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера возьмём задачу классификации на датасете [cedr](https://huggingface.co/datasets/cedr). Скачиваем и предобрабатываем датасет. В обучающих целях возьмем только те тексты, для которых определён ровно 1 класс (там встречаются примеры, для которых определены 0 классов или больше 1, они нам не нужны)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = punctuation + \"«»\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация\n",
    "Процесс разбиения текста на токены, то есть части этого текста.   \n",
    "Чем \"слово\" отличается от \"токена\": токен это более обобщенное понятие, то есть токенами являются не только слова, но еще и цифры, даты, смайлики и тд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ToktokTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Привет',\n",
       " '!',\n",
       " 'Как',\n",
       " 'твои',\n",
       " 'дела',\n",
       " '?',\n",
       " 'Чем',\n",
       " 'ты',\n",
       " 'занимаешься',\n",
       " '??',\n",
       " '?',\n",
       " '=',\n",
       " ')',\n",
       " ')']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('Привет! Как твои дела? Чем ты занимаешься ??? =))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: cedr/main\n",
      "Reusing dataset cedr (/Users/a19415907/.cache/huggingface/datasets/cedr/main/0.1.1/117570489cbabbdf8de619bd31918a1cd680a7f286b89d04af340d0691dc2d66)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f0e19c306e4915b7df61b23a53114e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus = load_dataset('cedr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4378"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = list()\n",
    "labels = list()\n",
    "\n",
    "for text, label in zip(corpus['train']['text'], corpus['train']['labels']):\n",
    "    if len(label) == 1:\n",
    "        texts.append(text)\n",
    "        labels.append(label[0])\n",
    "        \n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В датасете 5 классов\n"
     ]
    }
   ],
   "source": [
    "print(f'В датасете {len(set(labels))} классов')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы хотим использовать эмбеддинги для векторизации текстов. Но если мы просто прочитаем весь файл, в котором 2 миллиона векторов размерностью 300, это всё может не поместиться в память. Поэтому будем держать в памяти только вектора тех слов, которые реально есть в наших текстах. Мы прочитаем 100 000 первых слов и возьмем к ним эмббединги.\n",
    "\n",
    "----\n",
    "\n",
    "_Примечание_. Чем больше слов мы прочитаем, тем меньше шанс того, что мы не сможем обработать какое-то слово на проде. Так что здесь необходим компромисс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(file_path, pad_token='PAD', unk_token='UNK', max_words=100_000, verbose=True):\n",
    "    \n",
    "    vocab = dict()\n",
    "    embeddings = list()\n",
    "\n",
    "    with open(file_path) as file_object:\n",
    "\n",
    "        vocab_size, embedding_dim = file_object.readline().strip().split()\n",
    "\n",
    "        vocab_size = int(vocab_size)\n",
    "        embedding_dim = int(embedding_dim)\n",
    "\n",
    "        # в файле 1 000 000 слов с векторами, давайте ограничим для простоты этот словарь\n",
    "        max_words = vocab_size if max_words <= 0 else max_words\n",
    "\n",
    "        # добавим пад токен и эмбеддинг в нашу матрицу эмбеддингов и словарь\n",
    "        vocab[pad_token] = 0\n",
    "        embeddings.append(np.zeros(embedding_dim))\n",
    "\n",
    "        # добавим унк токен и эмбеддинг в нашу матрицу эмбеддингов и словарь\n",
    "        vocab[unk_token] = 1\n",
    "        embeddings.append(np.ones(embedding_dim))\n",
    "\n",
    "        progress_bar = tqdm(total=max_words, disable=not verbose, desc='Reading embeddings file')\n",
    "\n",
    "        for line in file_object:\n",
    "            parts = line.strip().split()\n",
    "\n",
    "            token = ' '.join(parts[:-embedding_dim]).lower()\n",
    "\n",
    "            if token in vocab:\n",
    "                continue\n",
    "\n",
    "            word_vector = np.array(list(map(float, parts[-embedding_dim:])))\n",
    "\n",
    "            vocab[token] = len(vocab)\n",
    "            embeddings.append(word_vector)\n",
    "\n",
    "            progress_bar.update()\n",
    "\n",
    "            if len(vocab) == max_words:\n",
    "                break\n",
    "\n",
    "        progress_bar.close()\n",
    "\n",
    "    embeddings = np.stack(embeddings)\n",
    "    \n",
    "    return vocab, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings file: 100%|█████████▉| 99998/100000 [00:08<00:00, 12371.74it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab, embeddings = load_embeddings('cc.ru.300.vec', max_words=100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNK\n",
    "\n",
    "В текстах есть неизвестные фасттексту токены. Их мы можем удалять или заменять на токен UNK. В данном случае возьмём в качестве неизвестного вектора вектор из единиц – это просто условность. \n",
    "\n",
    "Если бы мы не планировали дообучать вектора, то вместо UNK могли бы взять:\n",
    "- какой-то очень редкий токен из word2vec, который точно не встретится в текстах\n",
    "- среднее по нескольким эмбеддингам\n",
    "\n",
    "Но с этим могут возникнуть проблемы, поэтому надёжнее было бы просто выкидывать неизвестный токен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2token = {index: token for token, index in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_norms = np.linalg.norm(embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_nearest_neighbors(word, embeddings, emb_norms, vocab, index2token, k=5):\n",
    "    \n",
    "    if word not in vocab:\n",
    "        print('Not in vocab')\n",
    "        return\n",
    "    \n",
    "    word_index = vocab[word]\n",
    "\n",
    "    word_vector = embeddings[word_index]\n",
    "    word_vector = np.expand_dims(word_vector, 0)\n",
    "\n",
    "    scores = (word_vector @ embeddings.T)[0]\n",
    "    \n",
    "    # переводим в косинусы, поделив на нормы векторов\n",
    "    # эпсилон 1e-6 для того, чтобы не делить на 0\n",
    "    scores = scores / (emb_norms + 1e-6) / emb_norms[word_index]\n",
    "    \n",
    "    # 1:k+1 потому что первый вариант это само слово\n",
    "    for idx in scores.argsort()[::-1][1:k+1]:\n",
    "        print(f'Слово {index2token[idx]} близко на {scores[idx]:.2f} к слову {word}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово таня близко на 0.91 к слову аня\n",
      "Слово катя близко на 0.91 к слову аня\n",
      "Слово оля близко на 0.90 к слову аня\n",
      "Слово настя близко на 0.89 к слову аня\n",
      "Слово юля близко на 0.89 к слову аня\n"
     ]
    }
   ],
   "source": [
    "get_k_nearest_neighbors('аня', embeddings, emb_norms, vocab, index2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово бабушка близко на 0.83 к слову мама\n",
      "Слово мамочка близко на 0.80 к слову мама\n",
      "Слово дочка близко на 0.78 к слову мама\n",
      "Слово мать близко на 0.75 к слову мама\n",
      "Слово тетя близко на 0.74 к слову мама\n"
     ]
    }
   ],
   "source": [
    "get_k_nearest_neighbors('мама', embeddings, emb_norms, vocab, index2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово имеете близко на 0.71 к слову имею\n",
      "Слово имеешь близко на 0.69 к слову имею\n",
      "Слово имел близко на 0.67 к слову имею\n",
      "Слово имея близко на 0.63 к слову имею\n",
      "Слово могу близко на 0.62 к слову имею\n"
     ]
    }
   ],
   "source": [
    "get_k_nearest_neighbors('имею', embeddings, emb_norms, vocab, index2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово денежки близко на 0.82 к слову деньги\n",
      "Слово бабки близко на 0.69 к слову деньги\n",
      "Слово денежные близко на 0.67 к слову деньги\n",
      "Слово бабло близко на 0.65 к слову деньги\n",
      "Слово денег близко на 0.65 к слову деньги\n"
     ]
    }
   ],
   "source": [
    "get_k_nearest_neighbors('деньги', embeddings, emb_norms, vocab, index2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово мелодия близко на 0.71 к слову музыка\n",
      "Слово песня близко на 0.67 к слову музыка\n",
      "Слово музыку близко на 0.62 к слову музыка\n",
      "Слово поэзия близко на 0.61 к слову музыка\n",
      "Слово аранжировка близко на 0.61 к слову музыка\n"
     ]
    }
   ],
   "source": [
    "get_k_nearest_neighbors('музыка', embeddings, emb_norms, vocab, index2token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравним разные способы токенизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# про различия подробнее можно найти, например, здесь\n",
    "# https://stackoverflow.com/questions/50240029/nltk-wordpunct-tokenize-vs-word-tokenize\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4378/4378 [00:00<00:00, 108848.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мы не знаем 16672 слов из 56988 слов в датасете\n",
      "Что составляет 29.26% датасета\n",
      "\n",
      "Уникальных неизвестных слов: 11918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_n_words = 0\n",
    "unknown_words = list()\n",
    "\n",
    "for sample in tqdm(texts):\n",
    "    # токенизация по пробелу\n",
    "    tokens = sample.split()\n",
    "    \n",
    "    for tok in tokens:\n",
    "        # проверяем есть ли токен в нашем словаре\n",
    "        if tok not in vocab:\n",
    "            unknown_words.append(tok)\n",
    "            \n",
    "        total_n_words += 1\n",
    "        \n",
    "print(f'Мы не знаем {len(unknown_words)} слов из {total_n_words} слов в датасете')\n",
    "print(f'Что составляет {len(unknown_words) * 100 / total_n_words:.2f}% датасета')\n",
    "print()\n",
    "print(f'Уникальных неизвестных слов: {len(set(unknown_words))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4378/4378 [00:00<00:00, 64473.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мы не знаем 13043 слов из 66991 слов в датасете\n",
      "Что составляет 19.47% датасета\n",
      "\n",
      "Уникальных неизвестных слов: 7295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_n_words = 0\n",
    "unknown_words = list()\n",
    "\n",
    "for sample in tqdm(texts):\n",
    "    # токенизация\n",
    "    tokens = wordpunct_tokenize(sample)\n",
    "    \n",
    "    for tok in tokens:\n",
    "        # проверяем есть ли токен в нашем словаре\n",
    "        if tok not in vocab:\n",
    "            unknown_words.append(tok)\n",
    "            \n",
    "        total_n_words += 1\n",
    "        \n",
    "print(f'Мы не знаем {len(unknown_words)} слов из {total_n_words} слов в датасете')\n",
    "print(f'Что составляет {len(unknown_words) * 100 / total_n_words:.2f}% датасета')\n",
    "print()\n",
    "print(f'Уникальных неизвестных слов: {len(set(unknown_words))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4378/4378 [00:00<00:00, 7208.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мы не знаем 11407 слов из 69058 слов в датасете\n",
      "Что составляет 16.52% датасета\n",
      "\n",
      "Уникальных неизвестных слов: 7279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_n_words = 0\n",
    "unknown_words = list()\n",
    "\n",
    "for sample in tqdm(texts):\n",
    "    # токенизация\n",
    "    tokens = word_tokenize(sample)\n",
    "    \n",
    "    for tok in tokens:\n",
    "        # проверяем есть ли токен в нашем словаре\n",
    "        if tok not in vocab:\n",
    "            unknown_words.append(tok)\n",
    "            \n",
    "        total_n_words += 1\n",
    "        \n",
    "print(f'Мы не знаем {len(unknown_words)} слов из {total_n_words} слов в датасете')\n",
    "print(f'Что составляет {len(unknown_words) * 100 / total_n_words:.2f}% датасета')\n",
    "print()\n",
    "print(f'Уникальных неизвестных слов: {len(set(unknown_words))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4378/4378 [00:00<00:00, 17375.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мы не знаем 11604 слов из 68007 слов в датасете\n",
      "Что составляет 17.06% датасета\n",
      "\n",
      "Уникальных неизвестных слов: 7806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_n_words = 0\n",
    "unknown_words = list()\n",
    "\n",
    "for sample in tqdm(texts):\n",
    "    # токенизация\n",
    "    tokens = tokenizer.tokenize(sample)\n",
    "    \n",
    "    for tok in tokens:\n",
    "        # проверяем есть ли токен в нашем словаре\n",
    "        if tok not in vocab:\n",
    "            unknown_words.append(tok)\n",
    "            \n",
    "        total_n_words += 1\n",
    "        \n",
    "print(f'Мы не знаем {len(unknown_words)} слов из {total_n_words} слов в датасете')\n",
    "print(f'Что составляет {len(unknown_words) * 100 / total_n_words:.2f}% датасета')\n",
    "print()\n",
    "print(f'Уникальных неизвестных слов: {len(set(unknown_words))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В данном примере в качесте компромисса между скоростью и качеством возьмем `ToktokTokenizer()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Dataset, DataLoader\n",
    "\n",
    "Очень важная абстракция для торча.\n",
    "Мы всегда будем ее использовать, чтобы работать с данными.\n",
    "\n",
    "Dataset - класс, от которого нужно наследоваться, чтобы написать свой обработчик данных. Внутри него нужно реализовать два метода, \n",
    "о которых будет чуть ниже. То есть в данном классе вы описывает как нужно преобразовать ваши данные в торчовый формат. Перевести тексты \n",
    "в индексы слов и тд.\n",
    "\n",
    "DataLoader - класс, который будет за вас семплировать данные батчами. Это итератор, поэтому формат работы с ним примерно такой:\n",
    "```python\n",
    "for batch in data_loader:\n",
    "    ...\n",
    "```\n",
    "То есть на каждой итерации отдается по одному батчу данных. Итерирование заканчивается, когда вы пройдете все батчи.\n",
    "\n",
    "Зачем нужны эти абстракции? Чтобы упростить и унифицировать работу с данными.\n",
    "Вообще вы можете реализовать что-то свое, но это упрощение данной задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# игрушечный датасет\n",
    "# 121535 примера, 4 фичи, 3 класса\n",
    "some_data_x = np.random.rand(121535, 4)\n",
    "some_data_y = np.random.randint(3, size=(121535,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08390985, 0.73901492, 0.53839731, 0.08602887],\n",
       "       [0.65902384, 0.44442405, 0.94237867, 0.73012484],\n",
       "       [0.89205426, 0.62401704, 0.56258677, 0.8085014 ],\n",
       "       [0.28957367, 0.92751064, 0.44624601, 0.38509372],\n",
       "       [0.20312296, 0.99569099, 0.29115095, 0.18119811],\n",
       "       [0.20123462, 0.90599464, 0.86329834, 0.68147875],\n",
       "       [0.97337525, 0.383089  , 0.3071032 , 0.79541952],\n",
       "       [0.13137745, 0.88181408, 0.25298212, 0.10445733],\n",
       "       [0.81206587, 0.50075849, 0.09746288, 0.08488478],\n",
       "       [0.65241757, 0.42343821, 0.35027859, 0.55469096]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# просто рандомные цифры\n",
    "some_data_x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, ..., 1, 1, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# и классы\n",
    "some_data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример надобности\n",
    "Для обучения модели вам нужно подавать в нее батчи данных. Как бы могли это реализовать, если бы у нас не было Dataset и DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7596/7596 [00:00<00:00, 63592.05it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "for start_batch in tqdm(range(0, some_data_x.shape[0], batch_size)):\n",
    "    \n",
    "    # выделили подвыборку для x и y\n",
    "    x_batch = some_data_x[start_batch:start_batch + batch_size]\n",
    "    y_batch = some_data_y[start_batch:start_batch + batch_size]\n",
    "    \n",
    "    # перевели numpy.array в torch.Tensor\n",
    "    x_batch = torch.Tensor(x_batch)\n",
    "    y_batch = torch.Tensor(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3988, 0.3867, 0.7535, 0.1573],\n",
       "        [0.9263, 0.8980, 0.9717, 0.0502],\n",
       "        [0.6780, 0.1598, 0.2096, 0.8795],\n",
       "        [0.2334, 0.8950, 0.9819, 0.5237],\n",
       "        [0.8297, 0.0650, 0.5640, 0.1436],\n",
       "        [0.8200, 0.0888, 0.8296, 0.5728],\n",
       "        [0.3732, 0.5296, 0.4542, 0.6237],\n",
       "        [0.8561, 0.3099, 0.7064, 0.5035],\n",
       "        [0.8445, 0.7229, 0.9940, 0.8948],\n",
       "        [0.8224, 0.0968, 0.1955, 0.2978],\n",
       "        [0.4032, 0.4686, 0.4744, 0.9936],\n",
       "        [0.8036, 0.2887, 0.4401, 0.5896],\n",
       "        [0.5311, 0.7239, 0.3884, 0.2194],\n",
       "        [0.0986, 0.7204, 0.7350, 0.5810],\n",
       "        [0.9766, 0.0980, 0.1361, 0.5313]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это достаточно простой пример. Мы смогли справиться сами, но почти всегда обработка данных для подачи ее в модель делается сложнее. \n",
    "И некоторые вещи часто нужны более одного раза, например, если мы хотим каждую эпоху шафлить наши данные, чтобы получать разные батчи.\n",
    "Мы сможем это сделать, но для этого нам придется тащить с собой некоторый код из проекта в проект. К тому же совместная разработка или \n",
    "просто чтение чужого кода сильно упрощается, когда вы используете унифицированные форматы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перейдем к Dataset\n",
    "И обернем наши данные в этот обработчик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_x, data_y):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        # нужно обязательно определить эту функцию\n",
    "        # должна возвращать размер датасета\n",
    "        # нужен для DataLoader, чтобы семплировать батчи\n",
    "        \n",
    "        return len(self.data_x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # еще нужно определить этот метод\n",
    "        # то есть как мы будем доставать наши данные по индексу\n",
    "        \n",
    "        return self.data_x[idx], self.data_y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataset = ToyDataset(some_data_x, some_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0.20123462, 0.90599464, 0.86329834, 0.68147875]), 1),\n",
       " (array([0.53292551, 0.8284627 , 0.20675282, 0.79202086]), 2))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_dataset[5], some_dataset[467]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кажется, что смысла в этом нет, но это самый простой пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "В него мы можем задать некоторые параметры, например, батч сайз и нужно ли шафлить каждый новый проход по данным эти самые данные, \n",
    "чтобы получать разные батчи, то есть по разному компоновать эти батчи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_loader = DataLoader(some_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0743, 0.3899, 0.2710, 0.1958],\n",
       "        [0.4043, 0.2142, 0.6954, 0.2143],\n",
       "        [0.9368, 0.6142, 0.6360, 0.4866],\n",
       "        [0.0268, 0.1752, 0.0502, 0.4007],\n",
       "        [0.2839, 0.9535, 0.4708, 0.4747],\n",
       "        [0.8043, 0.9568, 0.9653, 0.5936],\n",
       "        [0.6977, 0.5088, 0.9580, 0.7959],\n",
       "        [0.1141, 0.9250, 0.4151, 0.7939],\n",
       "        [0.4814, 0.1534, 0.4067, 0.6722],\n",
       "        [0.4097, 0.2172, 0.0530, 0.3716],\n",
       "        [0.1891, 0.5164, 0.3446, 0.3382],\n",
       "        [0.5903, 0.6094, 0.9152, 0.9172],\n",
       "        [0.8977, 0.5235, 0.6368, 0.9912],\n",
       "        [0.2054, 0.4076, 0.3539, 0.4153],\n",
       "        [0.1628, 0.0358, 0.2724, 0.0508],\n",
       "        [0.7283, 0.3156, 0.9479, 0.7058]], dtype=torch.float64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x, y in some_loader:\n",
    "    break\n",
    "    \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 4])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x, y in some_loader:\n",
    "    pass\n",
    "\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# почему 15?\n",
    "# потому что количество наших данных нацело не делится на 16\n",
    "# и поэтому последний батч меньше 16-ти\n",
    "len(some_dataset) % 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Усложним обработчик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для чего это все? Внутри датасета мы можем делать все что угодно с нашими данными, см. функцию `__getitem__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_x, data_y):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        # нужно обязательно определить эту функцию\n",
    "        # должна возвращать размер датасета\n",
    "        # нужен для DataLoader, чтобы семплировать батчи\n",
    "        \n",
    "        return len(self.data_x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def pow_features(x, n=2):\n",
    "        \n",
    "        return x ** n\n",
    "    \n",
    "    @staticmethod\n",
    "    def log_features(x):\n",
    "        \n",
    "        return np.log(x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # еще нужно определить этот метод\n",
    "        # то есть как мы будем доставать наши данные по индексу\n",
    "        \n",
    "        x = self.data_x[idx]\n",
    "        \n",
    "        # внутри датасета мы можем делать все что угодно с нашими данными\n",
    "        # например выше определим функции, которые добавляют степенные фичи\n",
    "        x_p_2 = self.pow_features(x, n=2)\n",
    "        x_p_3 = self.pow_features(x, n=3)\n",
    "        # и еще возьмем логарифмические фичи\n",
    "        x_log = self.log_features(x)\n",
    "        \n",
    "        # сконкатенируем наши фичи\n",
    "        x = np.concatenate([x, x_p_2, x_p_3, x_log])\n",
    "        \n",
    "        y = self.data_y[idx]\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_dataset = ToyDataset(some_data_x, some_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_loader = DataLoader(dataset=toy_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in toy_loader: # заметим, что мы сразу получаем торчовый формат данных\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 16])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0839,  0.7390,  0.5384,  ..., -0.3024, -0.6192, -2.4531],\n",
       "        [ 0.6590,  0.4444,  0.9424,  ..., -0.8110, -0.0593, -0.3145],\n",
       "        [ 0.8921,  0.6240,  0.5626,  ..., -0.4716, -0.5752, -0.2126],\n",
       "        ...,\n",
       "        [ 0.2980,  0.5527,  0.0765,  ..., -0.5930, -2.5701, -0.1711],\n",
       "        [ 0.2624,  0.9566,  0.0393,  ..., -0.0444, -3.2358, -0.4102],\n",
       "        [ 0.8782,  0.6737,  0.2707,  ..., -0.3949, -1.3068, -1.7048]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 0, 1, 1, 1, 0, 0, 2, 0, 1, 2, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 2, 2,\n",
       "        2, 1, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 0, 2, 0, 1, 1, 1, 0, 2, 2, 1, 2,\n",
       "        2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 0, 2, 1, 1, 1, 2, 0, 2, 0, 1, 2, 2, 2,\n",
       "        2, 0, 2, 0, 2, 1, 0, 1, 0, 2, 0, 0, 0, 0, 0, 1, 1, 1, 2, 0, 2, 2, 2, 0,\n",
       "        2, 2, 1, 2, 2, 0, 2, 0, 0, 1, 2, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 1, 2, 1,\n",
       "        1, 1, 0, 0, 1, 2, 2, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.114852786064148"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сделаем небольшую модель и посчитаем лосс\n",
    "\n",
    "model = torch.nn.Sequential(torch.nn.Linear(16, 8),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(8, 4),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(4, 3))\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    prediction = model(x.float())\n",
    "\n",
    "    loss = criterion(prediction, y)\n",
    "    \n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Перейдем к нашим текстам\n",
    "Будем отдавать строку и таргет по индексу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, texts, targets):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        text = self.texts[index]\n",
    "        target = self.targets[index]\n",
    "        \n",
    "        return text, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextClassificationDataset(texts=texts, targets=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ С этим удивительным и снежным утром!'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Смысл обработчика\n",
    "Состоит в том, что нам нужно преобразовать наши данные в формат, который мы уже сможем передать в модель.\n",
    "Сейчас у нас строки, а торч ничего не знает про строки, ему нужны тензоры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем эмбеддинги\n",
    "Чтобы работать с текстовыми данными мы можем разбить наши строки на слова, а слова перевести в вектора. Мы говорили про такой метод как word2vec и в начале этой тетрадки загружали файл с этими самыми векторами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, texts, targets, vocab, tokenizer):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.vocab = vocab\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        \"\"\"\n",
    "        В этом методе нужно разделить строку текста на токены\n",
    "        НАПИСАТЬ КОД САМОМУ\n",
    "        \"\"\"\n",
    "        ...\n",
    "    \n",
    "    def indexing(self, tokenized_text):\n",
    "        \"\"\"\n",
    "        В этом методе нужно перевести список токенов в список с индексами этих токенов\n",
    "        НАПИСАТЬ КОД САМОМУ\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        text = self.texts[index]        \n",
    "        target = self.targets[index]\n",
    "        \n",
    "        # применить реализованные методы\n",
    "        tokenized_text = ...\n",
    "        \n",
    "        # переведем наши индексы токенов в торчовый тензор\n",
    "        # таргет переведется самостоятельно\n",
    "        tokenized_text = torch.tensor(tokenized_text)\n",
    "        \n",
    "        return tokenized_text, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextClassificationDataset(texts=texts, targets=labels, vocab=vocab, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 400, 29198, 4, 2311, 22]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['меня',\n",
       " 'остается',\n",
       " 'только',\n",
       " 'один',\n",
       " 'вопрос',\n",
       " '-',\n",
       " 'является',\n",
       " 'ли',\n",
       " 'этот',\n",
       " 'приступ',\n",
       " 'отчаяния',\n",
       " '(',\n",
       " 'а',\n",
       " 'точнее',\n",
       " 'приступ',\n",
       " 'удивления',\n",
       " ',',\n",
       " 'почему',\n",
       " 'мне',\n",
       " 'не',\n",
       " 'становится',\n",
       " 'лучше',\n",
       " ',',\n",
       " 'почему',\n",
       " 'мне',\n",
       " 'ничего',\n",
       " 'не',\n",
       " 'помогает',\n",
       " ')',\n",
       " 'еще',\n",
       " 'одним',\n",
       " 'испытанием',\n",
       " '?']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# мы можем восстановить текст обратно по индексам слов\n",
    "[index2token[idx.item()] for idx in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### У нас остается проблема разных длин текстов\n",
    "Чтобы поместить батч текстов в один тензор нам нужны одинаковые длины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "## это не отработает, можете раскомментировать и проверить\n",
    "\n",
    "# x = [\n",
    "#     [1, 2, 3],\n",
    "#     [1, 2, 3, 4, 5],\n",
    "#     [1, 2, 3, 4, 5, 6, 7]\n",
    "# ]\n",
    "\n",
    "# torch.tensor(x), torch.tensor(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 0, 0, 0, 0],\n",
       "         [1, 2, 3, 4, 5, 0, 0],\n",
       "         [1, 2, 3, 4, 5, 6, 7]]),\n",
       " torch.Size([3, 7]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# это сработает\n",
    "\n",
    "x = [\n",
    "    [1, 2, 3, 0, 0, 0, 0],\n",
    "    [1, 2, 3, 4, 5, 0, 0],\n",
    "    [1, 2, 3, 4, 5, 6, 7]\n",
    "]\n",
    "\n",
    "torch.tensor(x), torch.tensor(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Длина текста\n",
    "Нам нужно понять до какой длины нам падить каждый наш пример. \n",
    "Мы можем найти в наших данных максимальную длину примера в токенах и падить до этой длины, но у этого подхода есть минус:\n",
    "у нас могут быть несколько текстов с аномально большой длиной, то есть некоторые выбросы.  \n",
    "\n",
    "В таком случае нам легче ограничить длину этих текстов до определенной статистики по нашему датасет, то есть, например, 95% наших текстов\n",
    "длиной в 25 слов и нам этого достаточно. То есть мы ограничимся этой длиной, потому что почти весь датасет влезает в эту длину\n",
    "и нам не нужно будет падить до большой длины.\n",
    "\n",
    "Паддинг нужен нам для того, чтобы мы могли поместить разные примеры в один батч, но мы не хотим учитывать эти токены, то есть \n",
    "по сути это будут холостые прогоны и за счет этого компромисса, что бОльшая часть датасета не больше n слов мы можем оптимизировать \n",
    "наше обучение.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "> Почему бы нам просто не выкинуть эти длинные тексты?\n",
    "\n",
    "Дело в том, что мы хотим прийти к некоторому компромиссу между максимальной длиной и потерей информации. Если мы возьмем 95-й перцинтиль наших длин (то есть 95% наших текстов не больше n), то, выкинув остальные 5%, мы потеряем существенную часть примеров.\n",
    "С другой стороны может показаться неправильным ограничение длины и это действительно может сломать смысл примеры, но зачастую этим \n",
    "принебрегают."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4378/4378 [00:00<00:00, 19076.23it/s]\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(tokenizer.tokenize(sample)) for sample in tqdm(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Распределение длин'}, xlabel='Длина в токенах', ylabel='Count'>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.grid()\n",
    "plt.title(\"Распределение длин\")\n",
    "plt.xlabel(\"Длина в токенах\")\n",
    "sns.histplot(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# видим большие выбросы в данных\n",
    "# 97% наших текстов не больше вот стольки токенов\n",
    "np.percentile(lengths, 97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, texts, targets, vocab, tokenizer, pad_index=0, max_length=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.vocab = vocab\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        self.pad_index = pad_index\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        \"\"\"\n",
    "        В этом методе нужно разделить строку текста на токены\n",
    "        \"\"\"\n",
    "        ...\n",
    "    \n",
    "    def indexing(self, tokenized_text):\n",
    "        \"\"\"\n",
    "        В этом методе нужно перевести список токенов в список с индексами этих токенов\n",
    "        \"\"\"\n",
    "        ...\n",
    "        \n",
    "    def padding(self, tokens_indices):\n",
    "        \"\"\"\n",
    "        В этом методе нужно сделать длину tokens_indices равной self.max_length\n",
    "        Опционально убрать повторяющиеся unk'и\n",
    "        \"\"\"\n",
    "        ...\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        text = self.texts[index]        \n",
    "        target = self.targets[index]\n",
    "        \n",
    "        # применить реализованные методы\n",
    "        tokenized_text = ...\n",
    "        \n",
    "        tokenized_text = torch.tensor(tokenized_text)\n",
    "        \n",
    "        return tokenized_text, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextClassificationDataset(texts=texts, targets=labels, vocab=vocab, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  117,  1404,    56,   150,   283,    16,   124,   143,   148, 26614,\n",
       "        30773,     9,    28,  4495, 26614, 27742,     2,   551,   135,    13,\n",
       "          762,   287,     2,   551,   135,   309,    13,  1666,     8,    96,\n",
       "          554, 44141])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = dataset[0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['меня',\n",
       " 'остается',\n",
       " 'только',\n",
       " 'один',\n",
       " 'вопрос',\n",
       " '-',\n",
       " 'является',\n",
       " 'ли',\n",
       " 'этот',\n",
       " 'приступ',\n",
       " 'отчаяния',\n",
       " '(',\n",
       " 'а',\n",
       " 'точнее',\n",
       " 'приступ',\n",
       " 'удивления',\n",
       " ',',\n",
       " 'почему',\n",
       " 'мне',\n",
       " 'не',\n",
       " 'становится',\n",
       " 'лучше',\n",
       " ',',\n",
       " 'почему',\n",
       " 'мне',\n",
       " 'ничего',\n",
       " 'не',\n",
       " 'помогает',\n",
       " ')',\n",
       " 'еще',\n",
       " 'одним',\n",
       " 'испытанием']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[index2token[idx.item()] for idx in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  117,  1404,    56,  ...,    96,   554, 44141],\n",
       "        [   26,   334,     5,  ...,     0,     0,     0],\n",
       "        [    5, 36501,    24,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [   13,   627,     2,  ...,     0,     0,     0],\n",
       "        [13683,   117, 22663,  ...,     0,     0,     0],\n",
       "        [  145,    22,     0,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 3, 1, 1, 0, 1, 4, 2, 3, 0, 0, 4, 3, 1, 0, 2, 2, 0, 1, 3, 2, 0, 0,\n",
       "        2, 1, 1, 1, 3, 2, 2, 1, 0, 2, 2, 0, 0, 1, 0, 2, 4, 2, 1, 0, 2, 2, 1, 2,\n",
       "        1, 1, 0, 1, 0, 0, 2, 2, 1, 3, 1, 1, 4, 1, 1, 1, 0, 2, 2, 2, 2, 3, 1, 2,\n",
       "        3, 0, 0, 0, 1, 0, 3, 0, 0, 1, 1, 1, 0, 2, 0, 0, 1, 2, 0, 0, 1, 2, 3, 2,\n",
       "        0, 3, 0, 1, 2, 0, 2, 0, 0, 1, 0, 2, 2, 4, 1, 3, 2, 0, 1, 1, 1, 2, 0, 4,\n",
       "        1, 1, 0, 1, 2, 0, 3, 0])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как мы можем задавать слои"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = nn.Embedding(num_embeddings=len(vocab), \n",
    "                               embedding_dim=embeddings.shape[-1],\n",
    "                               padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embed = embedding_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5558, -0.3845,  0.6288,  ...,  1.1814,  1.1737, -1.4745],\n",
       "         [ 0.1189,  0.6188, -0.8129,  ...,  0.6150,  0.9907, -0.3969],\n",
       "         [-0.5489,  0.8639, -1.1233,  ..., -0.3596,  0.4887, -0.1349],\n",
       "         ...,\n",
       "         [ 0.6380,  1.0028,  3.1059,  ...,  2.1019, -0.4031, -1.0203],\n",
       "         [ 0.2955,  1.1834,  0.7488,  ...,  0.1164, -1.1229,  0.0054],\n",
       "         [ 1.0405, -1.4342, -0.2350,  ..., -1.7457, -0.5119, -0.4866]],\n",
       "\n",
       "        [[-0.0097,  0.1318, -1.2308,  ...,  1.1959, -1.9039, -1.0761],\n",
       "         [-0.9444, -1.9919,  0.1381,  ...,  0.3196, -0.4700, -0.8495],\n",
       "         [-0.9584, -1.8450,  0.3403,  ...,  0.9486, -1.1075, -2.2496],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.9584, -1.8450,  0.3403,  ...,  0.9486, -1.1075, -2.2496],\n",
       "         [-0.8337, -0.2309,  0.4286,  ...,  1.8974,  1.5609,  0.5593],\n",
       "         [-0.3002,  0.6939, -0.4466,  ..., -1.1455, -0.1956, -0.7095],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.6964,  0.3006,  2.0981,  ..., -0.4922, -0.0596, -1.7596],\n",
       "         [ 2.0188, -1.5775, -0.6051,  ...,  0.4166,  0.8893, -0.6508],\n",
       "         [ 1.1724, -0.4424, -0.5904,  ...,  0.7637, -1.3822, -0.4215],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.4856,  1.3673, -0.5131,  ...,  0.9028,  2.3284, -0.4154],\n",
       "         [ 0.5558, -0.3845,  0.6288,  ...,  1.1814,  1.1737, -1.4745],\n",
       "         [-1.7827, -1.1239, -1.5613,  ..., -1.0263, -1.3525, -0.6243],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.3953, -0.4807,  0.0195,  ..., -0.0731, -1.0228,  1.0924],\n",
       "         [-0.5984,  0.0600,  0.2783,  ..., -0.6301, -0.4100, -0.7051],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 32, 300])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Но мы ведь прочитали нашу матрицу эмбеддингов\n",
    "Таким образом она инициализируется предобученными весами.  \n",
    "При такой инициализации по умолчанию она замораживается, внутри ```.from_pretrained(embeddings, padding_idx=0)``` есть флаг ```freeze```, который отвечает за необходимость заморозки весов. То есть эти веса в процессе обучения не будут обновляться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Куда класть матрицу с эмбеддингами?\n",
    "\n",
    "Когда вы будете писать нейросеть с использованием предобученных эмбеддингов, первым слоем вы будете ставить слой `torch.nn.Embedding`, в него можно передать наши `embeddings`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(100000, 300)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0634, -0.0167,  0.0164,  ...,  0.0535, -0.1033, -0.0389],\n",
       "         [-0.0069, -0.0333,  0.0019,  ...,  0.0033, -0.0497, -0.0286],\n",
       "         [ 0.0192, -0.0201,  0.0092,  ...,  0.0232,  0.0039,  0.0450],\n",
       "         ...,\n",
       "         [ 0.0426, -0.0186, -0.0137,  ...,  0.0284, -0.0346, -0.0550],\n",
       "         [ 0.0335, -0.0442,  0.0347,  ...,  0.0295,  0.0100, -0.0767],\n",
       "         [-0.0268, -0.0005,  0.0292,  ...,  0.0523, -0.0420, -0.0436]],\n",
       "\n",
       "        [[-0.0212, -0.0543, -0.0353,  ...,  0.1210,  0.0972, -0.0095],\n",
       "         [ 0.0235, -0.0666, -0.0306,  ...,  0.0155,  0.0372, -0.0864],\n",
       "         [ 0.0205,  0.0438,  0.0254,  ...,  0.0174,  0.3094,  0.3463],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0205,  0.0438,  0.0254,  ...,  0.0174,  0.3094,  0.3463],\n",
       "         [ 0.0028, -0.0477, -0.0699,  ..., -0.0574, -0.0777, -0.0311],\n",
       "         [-0.0990,  0.0666, -0.0998,  ...,  0.1271, -0.0152,  0.3744],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0238,  0.0174, -0.0431,  ...,  0.1375, -0.1223, -0.2806],\n",
       "         [ 0.0187, -0.0872, -0.0113,  ...,  0.0228, -0.0400, -0.1235],\n",
       "         [-0.0326, -0.1499,  0.0232,  ..., -0.0237, -0.0261, -0.1832],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.1022, -0.1516,  0.0087,  ...,  0.0433, -0.0726,  0.0034],\n",
       "         [ 0.0634, -0.0167,  0.0164,  ...,  0.0535, -0.1033, -0.0389],\n",
       "         [-0.0626,  0.0264,  0.0588,  ...,  0.0263, -0.0775, -0.0637],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0393, -0.0498,  0.0183,  ..., -0.1143,  0.1164,  0.0861],\n",
       "         [-0.0077,  0.2507, -0.2472,  ...,  0.0817,  0.0934, -0.3849],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 32, 300])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_layer(x).shape  # (batch_size, seq_len, emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
